# ReVideo: Remake a Video with Motion and Content Control
[Chong Mou](https://scholar.google.com/citations?user=SYQoDk0AAAAJ&hl=zh-CN),
[Mingdeng Cao](https://scholar.google.com/citations?user=EcS0L5sAAAAJ&hl=en),
[Xintao Wang](https://xinntao.github.io/),
[Zhaoyang Zhang](https://zzyfd.github.io/),
[Ying Shan](https://scholar.google.com/citations?user=4oXBp9UAAAAJ),
[Jian Zhang](https://jianzhang.tech/)

[![Project page](https://img.shields.io/badge/Project-Page-brightgreen)](https://mc-e.github.io/project/ReVideo/)

---
## Introduction
ReVideo aims to solve the problem of local video editing. The editing target includes visual content and motion trajectory modifications.
<p align="center">
  <img src="asserts/teaser.png">
</p>

## üì∞ **New Features/Updates**
- [2024/05/20] Paper of **ReVideo** is available [here]().

## ‚úèÔ∏è Todo
- [ ] Code will be open sourced in June

https://github.com/MC-E/DragonDiffusion/assets/54032224/222f35da-7396-4989-a3c3-9ab4a2e5fa98

## üî•üî•üî• Main Features
### Change content & Customize motion trajectoy

<figure>
    <video poster="" id="chair-tp" autoplay controls muted loop playsinline width="45%">
    <source src="https://github.com/MC-E/DragonDiffusion/assets/54032224/222f35da-7396-4989-a3c3-9ab4a2e5fa98"
            type="video/mp4">
    </video>
    <video poster="" id="chair-tp" autoplay controls muted loop playsinline width="45%">
    <source src="https://github.com/MC-E/DragonDiffusion/assets/54032224/222f35da-7396-4989-a3c3-9ab4a2e5fa98"
            type="video/mp4">
    </video>
    <figcaption>Original video (Left) & Editing results (Right)</figcaption>
</figure>

## Related Works
<p>
[1] <a href="https://pika.art/">https://pika.art/</a>
</p>
<p>
[2] <a href="https://arxiv.org/abs/2308.08089">DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory</a>
</p>
<p>
[3] <a href="https://arxiv.org/abs/2403.07420">
    DragAnything: Motion Control for Anything using Entity Representation</a>
</p>
<p>
[4] <a href="https://arxiv.org/abs/2403.14468/">AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks</a>
</p>

# ü§ó Acknowledgements
We appreciate the relasing code of [Stable Video Diffusion](https://github.com/Stability-AI/generative-models).
