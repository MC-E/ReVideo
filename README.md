# ReVideo: Remake a Video with Motion and Content Control
[Chong Mou](https://scholar.google.com/citations?user=SYQoDk0AAAAJ&hl=zh-CN),
[Mingdeng Cao](https://scholar.google.com/citations?user=EcS0L5sAAAAJ&hl=en),
[Xintao Wang](https://xinntao.github.io/),
[Zhaoyang Zhang](https://zzyfd.github.io/),
[Ying Shan](https://scholar.google.com/citations?user=4oXBp9UAAAAJ),
[Jian Zhang](https://jianzhang.tech/)

[![Project page](https://img.shields.io/badge/Project-Page-brightgreen)](https://mc-e.github.io/project/ReVideo/)

---
## Introduction
ReVideo aims to solve the problem of local video editing. The editing target includes visual content and motion trajectory modifications.
<p align="center">
  <img src="asserts/teaser.png">
</p>

## üì∞ **New Features/Updates**
- [2024/05/20] Paper of **ReVideo** is available [here]().

## ‚úèÔ∏è Todo
- [ ] Code will be open sourced in June

## üî•üî•üî• Main Features
### Change content & Customize motion trajectoy
<!-- <iframe width="45%" src="asserts/desert" allowfullscreen></iframe>
<iframe width="45%" src="https://github.com/MC-E/DragonDiffusion/assets/54032224/222f35da-7396-4989-a3c3-9ab4a2e5fa98" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
<table class="center">
<tr>
  <td style="text-align:center;"><b>Input Video</b></td>
  <td style="text-align:center;"><b>Output Video</b></td>
</tr>
<tr>
  <td><video src="https://github.com/MC-E/DragonDiffusion/assets/54032224/222f35da-7396-4989-a3c3-9ab4a2e5fa98" allow="autoplay"></td>
  <td><video src="https://github.com/MC-E/DragonDiffusion/assets/54032224/222f35da-7396-4989-a3c3-9ab4a2e5fa98"></td>
</tr>
</table>

## Related Works
<p>
[1] <a href="https://pika.art/">https://pika.art/</a>
</p>
<p>
[2] <a href="https://arxiv.org/abs/2308.08089">DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory</a>
</p>
<p>
[3] <a href="https://arxiv.org/abs/2403.07420">
    DragAnything: Motion Control for Anything using Entity Representation</a>
</p>
<p>
[4] <a href="https://arxiv.org/abs/2403.14468/">AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks</a>
</p>

# ü§ó Acknowledgements
We appreciate the relasing code of [Stable Video Diffusion](https://github.com/Stability-AI/generative-models).
